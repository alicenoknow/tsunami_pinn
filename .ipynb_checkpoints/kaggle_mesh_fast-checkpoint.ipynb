{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6774114,"sourceType":"datasetVersion","datasetId":3897798},{"sourceId":6883680,"sourceType":"datasetVersion","datasetId":3954917},{"sourceId":7060245,"sourceType":"datasetVersion","datasetId":4064500}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Pawel Maczuga and Maciej Paszynski 2023\n\nimport meshio\nimport numpy as np\nimport torch\n\nfrom datetime import datetime\nfrom torch import nn\nfrom typing import Callable, Tuple, List\n# from utils import get_initial_points, plot_intial_condition, plot_simulation_by_frame, create_gif, ReportContext, create_report, plot_running_average","metadata":{"execution":{"iopub.status.busy":"2023-11-29T22:48:44.716360Z","iopub.execute_input":"2023-11-29T22:48:44.716715Z","iopub.status.idle":"2023-11-29T22:48:44.827810Z","shell.execute_reply.started":"2023-11-29T22:48:44.716682Z","shell.execute_reply":"2023-11-29T22:48:44.827076Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!pip install meshio\n!pip install xhtml2pdf\n!mkdir img\n!mkdir results","metadata":{"execution":{"iopub.status.busy":"2023-11-29T22:47:40.748623Z","iopub.execute_input":"2023-11-29T22:47:40.749235Z","iopub.status.idle":"2023-11-29T22:48:44.714246Z","shell.execute_reply.started":"2023-11-29T22:47:40.749206Z","shell.execute_reply":"2023-11-29T22:48:44.712758Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting meshio\n  Downloading meshio-5.3.4-py3-none-any.whl (167 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.7/167.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from meshio) (1.24.3)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from meshio) (13.5.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->meshio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->meshio) (2.16.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->meshio) (0.1.0)\nInstalling collected packages: meshio\nSuccessfully installed meshio-5.3.4\nCollecting xhtml2pdf\n  Obtaining dependency information for xhtml2pdf from https://files.pythonhosted.org/packages/1d/b7/637d96fe25024fdaaa4d265ae353cafdca706167325109fc1e574174b2bf/xhtml2pdf-0.2.13-py3-none-any.whl.metadata\n  Downloading xhtml2pdf-0.2.13-py3-none-any.whl.metadata (21 kB)\nCollecting arabic-reshaper>=3.0.0 (from xhtml2pdf)\n  Downloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\nRequirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.10/site-packages (from xhtml2pdf) (1.1)\nRequirement already satisfied: Pillow>=8.1.1 in /opt/conda/lib/python3.10/site-packages (from xhtml2pdf) (10.1.0)\nCollecting pyHanko>=0.12.1 (from xhtml2pdf)\n  Obtaining dependency information for pyHanko>=0.12.1 from https://files.pythonhosted.org/packages/68/fc/d3d6dbb6ca6a9c755df5b6a1f2897e7560ef4c1384d8c89d182424f1582e/pyHanko-0.21.0-py3-none-any.whl.metadata\n  Downloading pyHanko-0.21.0-py3-none-any.whl.metadata (9.4 kB)\nCollecting pyhanko-certvalidator>=0.19.5 (from xhtml2pdf)\n  Obtaining dependency information for pyhanko-certvalidator>=0.19.5 from https://files.pythonhosted.org/packages/12/72/9d5d45d5dee498003c9e4aceb0161f7d5e97cf7d2dc26f4802557fac39d6/pyhanko_certvalidator-0.26.2-py3-none-any.whl.metadata\n  Downloading pyhanko_certvalidator-0.26.2-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: pypdf>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from xhtml2pdf) (3.17.0)\nRequirement already satisfied: python-bidi>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from xhtml2pdf) (0.4.2)\nCollecting reportlab[pycairo]>=4.0.4 (from xhtml2pdf)\n  Obtaining dependency information for reportlab[pycairo]>=4.0.4 from https://files.pythonhosted.org/packages/60/8b/fdd40ce4206bab7c8034f70925b8735c6fd57334d81e8aea9cfd0eb18603/reportlab-4.0.7-py3-none-any.whl.metadata\n  Downloading reportlab-4.0.7-py3-none-any.whl.metadata (1.3 kB)\nCollecting svglib>=1.2.1 (from xhtml2pdf)\n  Downloading svglib-1.5.1.tar.gz (913 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.9/913.9 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->xhtml2pdf) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->xhtml2pdf) (0.5.1)\nCollecting asn1crypto>=1.5.1 (from pyHanko>=0.12.1->xhtml2pdf)\n  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting qrcode>=7.3.1 (from pyHanko>=0.12.1->xhtml2pdf)\n  Downloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tzlocal>=4.3 in /opt/conda/lib/python3.10/site-packages (from pyHanko>=0.12.1->xhtml2pdf) (5.2)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from pyHanko>=0.12.1->xhtml2pdf) (8.1.7)\nRequirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from pyHanko>=0.12.1->xhtml2pdf) (2.31.0)\nRequirement already satisfied: pyyaml>=6.0 in /opt/conda/lib/python3.10/site-packages (from pyHanko>=0.12.1->xhtml2pdf) (6.0.1)\nCollecting cryptography>=41.0.5 (from pyHanko>=0.12.1->xhtml2pdf)\n  Obtaining dependency information for cryptography>=41.0.5 from https://files.pythonhosted.org/packages/62/bd/69628ab50368b1beb900eb1de5c46f8137169b75b2458affe95f2f470501/cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl.metadata\n  Downloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (5.2 kB)\nCollecting oscrypto>=1.1.0 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf)\n  Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting uritools>=3.0.1 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf)\n  Obtaining dependency information for uritools>=3.0.1 from https://files.pythonhosted.org/packages/6b/ff/b16f225ceeb47f5d8899371ce446a8d6c1fe509a8882998b869f2a794c25/uritools-4.0.2-py3-none-any.whl.metadata\n  Downloading uritools-4.0.2-py3-none-any.whl.metadata (4.7 kB)\nCollecting rlPyCairo<1,>=0.2.0 (from reportlab[pycairo]>=4.0.4->xhtml2pdf)\n  Obtaining dependency information for rlPyCairo<1,>=0.2.0 from https://files.pythonhosted.org/packages/3d/d6/0f52d7f85e14429124651a3e4db8b50b1ec860b674648e34a8d5e0861771/rlPyCairo-0.3.0-py3-none-any.whl.metadata\n  Downloading rlPyCairo-0.3.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting freetype-py<2.4,>=2.3.0 (from reportlab[pycairo]>=4.0.4->xhtml2pdf)\n  Downloading freetype_py-2.3.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (978 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.9/978.9 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from svglib>=1.2.1->xhtml2pdf) (4.9.3)\nRequirement already satisfied: tinycss2>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from svglib>=1.2.1->xhtml2pdf) (1.2.1)\nCollecting cssselect2>=0.2.0 (from svglib>=1.2.1->xhtml2pdf)\n  Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf) (1.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qrcode>=7.3.1->pyHanko>=0.12.1->xhtml2pdf) (4.5.0)\nCollecting pypng (from qrcode>=7.3.1->pyHanko>=0.12.1->xhtml2pdf)\n  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf) (2023.7.22)\nCollecting pycairo>=1.20.0 (from rlPyCairo<1,>=0.2.0->reportlab[pycairo]>=4.0.4->xhtml2pdf)\n  Downloading pycairo-1.25.1.tar.gz (347 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.1/347.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf) (2.21)\nDownloading xhtml2pdf-0.2.13-py3-none-any.whl (124 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyHanko-0.21.0-py3-none-any.whl (433 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.2/433.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyhanko_certvalidator-0.26.2-py3-none-any.whl (109 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading rlPyCairo-0.3.0-py3-none-any.whl (7.5 kB)\nDownloading uritools-4.0.2-py3-none-any.whl (10 kB)\nDownloading reportlab-4.0.7-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: svglib, pycairo\n  Building wheel for svglib (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for svglib: filename=svglib-1.5.1-py3-none-any.whl size=30904 sha256=a272d2042601cc6f8cac1f4949fb2a012332aa81fe04bb6c0ceaab4c494ec825\n  Stored in directory: /root/.cache/pip/wheels/56/9f/90/f37f4b9dbf82987a24ae14f15586e96715cb669a4710b3b85d\n  Building wheel for pycairo (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycairo: filename=pycairo-1.25.1-cp310-cp310-linux_x86_64.whl size=147893 sha256=155cf9176a51ff8b3ca5d6a7bef94c3fd860fc437e23173d2f6fa32aa36166c5\n  Stored in directory: /root/.cache/pip/wheels/d6/d8/c4/9bb1adbc349a349ed4718627f0afffeae26d9982060568cd30\nSuccessfully built svglib pycairo\nInstalling collected packages: pypng, asn1crypto, arabic-reshaper, uritools, reportlab, qrcode, pycairo, oscrypto, freetype-py, rlPyCairo, cssselect2, cryptography, svglib, pyhanko-certvalidator, pyHanko, xhtml2pdf\n  Attempting uninstall: cryptography\n    Found existing installation: cryptography 41.0.3\n    Uninstalling cryptography-41.0.3:\n      Successfully uninstalled cryptography-41.0.3\nSuccessfully installed arabic-reshaper-3.0.0 asn1crypto-1.5.1 cryptography-41.0.7 cssselect2-0.7.0 freetype-py-2.3.0 oscrypto-1.3.0 pyHanko-0.21.0 pycairo-1.25.1 pyhanko-certvalidator-0.26.2 pypng-0.20220715.0 qrcode-7.4.2 reportlab-4.0.7 rlPyCairo-0.3.0 svglib-1.5.1 uritools-4.0.2 xhtml2pdf-0.2.13\n","output_type":"stream"}]},{"cell_type":"code","source":"MESH_FILENAME = \"/kaggle/input/meshvalpara/val_square_UTM_translated_4.inp\" ","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:45.810850Z","iopub.execute_input":"2023-11-29T23:53:45.811821Z","iopub.status.idle":"2023-11-29T23:53:45.815906Z","shell.execute_reply.started":"2023-11-29T23:53:45.811786Z","shell.execute_reply":"2023-11-29T23:53:45.814966Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.132974Z","iopub.execute_input":"2023-11-29T23:53:46.133580Z","iopub.status.idle":"2023-11-29T23:53:46.139361Z","shell.execute_reply.started":"2023-11-29T23:53:46.133553Z","shell.execute_reply":"2023-11-29T23:53:46.138395Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.153364Z","iopub.execute_input":"2023-11-29T23:53:46.153894Z","iopub.status.idle":"2023-11-29T23:53:46.159739Z","shell.execute_reply.started":"2023-11-29T23:53:46.153868Z","shell.execute_reply":"2023-11-29T23:53:46.158815Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"RUN_NUM = 6","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.176111Z","iopub.execute_input":"2023-11-29T23:53:46.176647Z","iopub.status.idle":"2023-11-29T23:53:46.180106Z","shell.execute_reply.started":"2023-11-29T23:53:46.176621Z","shell.execute_reply":"2023-11-29T23:53:46.179222Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"### Parameters","metadata":{}},{"cell_type":"code","source":"## LENGTH = 1. # Domain size in x axis. Always starts at 0\nTOTAL_TIME = 0.5 # Domain size in t axis. Always starts at 0\nN_POINTS = 15 # Number of in single asxis\nN_POINTS_PLOT = 100 # Number of points in single axis used in plotting\n\nWEIGHT_RESIDUAL = 0.05 # Weight of residual part of loss function\nWEIGHT_INITIAL = 3 # Weight of initial part of loss function\nWEIGHT_BOUNDARY = 0.0005 # Weight of boundary part of loss function\n\n# Original\n# WEIGHT_RESIDUAL = 0.03 # Weight of residual part of loss function\n# WEIGHT_INITIAL = 1.0 # Weight of initial part of loss function\n# WEIGHT_BOUNDARY = 0.0005 # Weight of boundary part of loss function\n\nLAYERS = 10\nNEURONS_PER_LAYER = 120\nEPOCHS = 50_000\nLEARNING_RATE = 0.00005\nGRAVITY = 9.81","metadata":{"id":"yRUNbvoDoDU9","execution":{"iopub.status.busy":"2023-11-29T23:53:46.199267Z","iopub.execute_input":"2023-11-29T23:53:46.199547Z","iopub.status.idle":"2023-11-29T23:53:46.204900Z","shell.execute_reply.started":"2023-11-29T23:53:46.199523Z","shell.execute_reply":"2023-11-29T23:53:46.203900Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"t_domain = [0, TOTAL_TIME]","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.246814Z","iopub.execute_input":"2023-11-29T23:53:46.247088Z","iopub.status.idle":"2023-11-29T23:53:46.250947Z","shell.execute_reply.started":"2023-11-29T23:53:46.247064Z","shell.execute_reply":"2023-11-29T23:53:46.250058Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def floor(x, y):\n    \"\"\"Get the sea floor value\"\"\"\n    return 2","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.267465Z","iopub.execute_input":"2023-11-29T23:53:46.267729Z","iopub.status.idle":"2023-11-29T23:53:46.271770Z","shell.execute_reply.started":"2023-11-29T23:53:46.267705Z","shell.execute_reply":"2023-11-29T23:53:46.270746Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"mesh = meshio.avsucd.read(MESH_FILENAME)\nvertices = torch.tensor(mesh.points, dtype=torch.float32)  # Tensor of vertices' coordinates\ntriangles = mesh.cells_dict['triangle']  # Connectivity information for triangles as NumPy array\n\nprint(vertices.shape)\n\n# Function to compute partial derivatives at vertices\ndef compute_derivatives_at_vertices(vertices, triangles):\n    dx_vertices = torch.zeros(vertices.shape[0])  # Initialize tensors for derivatives\n    dy_vertices = torch.zeros(vertices.shape[0])\n\n    for triangle in triangles:\n        # Extract vertex indices for the current triangle\n        idx1, idx2, idx3 = triangle\n        \n        # Vertices' coordinates for the current triangle\n        v1, v2, v3 = vertices[idx1], vertices[idx2], vertices[idx3]\n        \n        # Compute partial derivatives (approximate gradient using cross product of edges)\n        dx = torch.cross(v2 - v1, v3 - v1)[0] / 2  # x-component of the cross product\n        dy = torch.cross(v2 - v1, v3 - v1)[1] / 2  # y-component of the cross product\n        \n        # Add computed derivatives to the corresponding vertices\n        dx_vertices[idx1] += dx\n        dx_vertices[idx2] += dx\n        dx_vertices[idx3] += dx\n        \n        dy_vertices[idx1] += dy\n        dy_vertices[idx2] += dy\n        dy_vertices[idx3] += dy\n\n    return dx_vertices.to(device), dy_vertices.to(device)\n\n# Compute derivatives at vertices\ndx_vertices, dy_vertices = compute_derivatives_at_vertices(vertices, triangles)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.296348Z","iopub.execute_input":"2023-11-29T23:53:46.296868Z","iopub.status.idle":"2023-11-29T23:53:46.317596Z","shell.execute_reply.started":"2023-11-29T23:53:46.296844Z","shell.execute_reply":"2023-11-29T23:53:46.316743Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"torch.Size([25, 3])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## PINN","metadata":{}},{"cell_type":"code","source":"class PINN(nn.Module):\n    \"\"\"Simple neural network accepting two features as input and returning a single output\n\n    In the context of PINNs, the neural network is used as universal function approximator\n    to approximate the solution of the differential equation\n    \"\"\"\n    def __init__(self, num_hidden: int, dim_hidden: int, act=nn.Tanh()):\n\n        super().__init__()\n\n        self.layer_in = nn.Linear(3, dim_hidden)\n        self.layer_out = nn.Linear(dim_hidden, 1)\n\n        num_middle = num_hidden - 1\n        self.middle_layers = nn.ModuleList(\n            [nn.Linear(dim_hidden, dim_hidden) for _ in range(num_middle)]\n        )\n        self.act = act\n\n    def forward(self, x, y, t):\n        x_stack = torch.cat([x, y, t], dim=1).to(device)\n        out = self.act(self.layer_in(x_stack))\n        for layer in self.middle_layers:\n            out = self.act(layer(out))\n        logits = self.layer_out(out)\n        return logits\n\n    def device(self):\n        return next(self.parameters()).device\n\n\ndef f(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n    \"\"\"Compute the value of the approximate solution from the NN model\"\"\"\n    return pinn(x, y, t)\n\n\ndef df(output: torch.Tensor, input: torch.Tensor, order: int = 1) -> torch.Tensor:\n    \"\"\"Compute neural network derivative with respect to input features using PyTorch autograd engine\"\"\"\n    df_value = output\n    for _ in range(order):\n        df_value = torch.autograd.grad(\n            df_value,\n            input,\n            grad_outputs=torch.ones_like(input),\n            create_graph=True,\n            retain_graph=True,\n        )[0]\n\n    return df_value\n\n\ndef dfdt(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor, f_val=None, order: int = 1):\n    f_value = f_val if f_val is not None else f(pinn, x, y, t)\n    # f_value = f(pinn, x, y, t)\n    return df(f_value, t, order=order)\n\n\ndef dfdx(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor, f_val=None, order: int = 1):\n    # f_value = f(pinn, x, y, t)\n    f_value = f_val if f_val is not None else f(pinn, x, y, t)\n    return df(f_value, x, order=order)\n\ndef dfdy(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor, f_val=None, order: int = 1):\n    # f_value = f(pinn, x, y, t)\n    f_value = f_val if f_val is not None else f(pinn, x, y, t)\n    return df(f_value, y, order=order)\n\ndef dzdx(x: torch.Tensor, y: torch.Tensor, order: int = 1):\n    return dx_vertices\n\ndef dzdy(x: torch.Tensor, y: torch.Tensor, order: int = 1):\n    return dy_vertices","metadata":{"id":"iO0Bk6pp5-oz","execution":{"iopub.status.busy":"2023-11-29T23:53:46.402339Z","iopub.execute_input":"2023-11-29T23:53:46.402623Z","iopub.status.idle":"2023-11-29T23:53:46.418915Z","shell.execute_reply.started":"2023-11-29T23:53:46.402599Z","shell.execute_reply":"2023-11-29T23:53:46.417986Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"## Loss function","metadata":{"id":"FPaX88HM6bTH"}},{"cell_type":"code","source":"def get_initial_points(x_domain: List[float], \n                       y_domain: List[float], \n                       t_domain: List[float], \n                       n_points: int, \n                       device=torch.device(\"cpu\"), \n                       requires_grad=True):\n    x_linspace = torch.linspace(x_domain[0], x_domain[1], n_points)\n    y_linspace = torch.linspace(y_domain[0], y_domain[1], n_points)\n    \n    x_grid, y_grid = torch.meshgrid(x_linspace, y_linspace, indexing=\"ij\")\n    \n    x_grid = x_grid.reshape(-1, 1).to(device)\n    y_grid = y_grid.reshape(-1, 1).to(device)\n    \n    x_grid.requires_grad = requires_grad\n    y_grid.requires_grad = requires_grad\n    \n    t0 = torch.full_like(x_grid, t_domain[0], requires_grad=requires_grad)\n    return (x_grid, y_grid, t0)\n\ndef get_initial_mesh(x_domain: List[float], \n                       y_domain: List[float], \n                       t_domain: List[float], \n                       n_points: int, \n                       device=torch.device(\"cpu\"), \n                       requires_grad=True):\n    x_raw, y_raw, _ = dump_points(MESH_FILENAME)\n    x = x_raw.to(device)\n    y = y_raw.to(device)\n    \n    x.requires_grad = requires_grad\n    y.requires_grad = requires_grad\n\n    x = x.reshape(-1, 1).to(device)\n    y = y.reshape(-1, 1).to(device)\n    \n    t0 = torch.full_like(x, t_domain[0], requires_grad=requires_grad)\n    return (x, y, t0)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.423294Z","iopub.execute_input":"2023-11-29T23:53:46.423926Z","iopub.status.idle":"2023-11-29T23:53:46.435274Z","shell.execute_reply.started":"2023-11-29T23:53:46.423895Z","shell.execute_reply":"2023-11-29T23:53:46.434483Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def get_boundary_points(x_domain, y_domain, t_domain, n_points, device = torch.device(\"cpu\"), requires_grad=True):\n    \"\"\"\n         .+------+\n       .' |    .'|\n      +---+--+'  |\n      |   |  |   |\n    y |  ,+--+---+\n      |.'    | .' t\n      +------+'\n         x\n    \"\"\"\n    x_linspace = torch.linspace(x_domain[0], x_domain[1], n_points)\n    y_linspace = torch.linspace(y_domain[0], y_domain[1], n_points)\n    t_linspace = torch.linspace(t_domain[0], t_domain[1], n_points)\n\n    x_grid, t_grid = torch.meshgrid(x_linspace, t_linspace, indexing=\"ij\")\n    y_grid, _      = torch.meshgrid(y_linspace, t_linspace, indexing=\"ij\")\n\n    x_grid = x_grid.reshape(-1, 1).to(device)\n    y_grid = y_grid.reshape(-1, 1).to(device)\n    t_grid = t_grid.reshape(-1, 1).to(device)\n    \n    x_grid.requires_grad = requires_grad\n    y_grid.requires_grad = requires_grad\n    t_grid.requires_grad = requires_grad\n\n    x0 = torch.full_like(t_grid, x_domain[0], requires_grad=requires_grad)\n    x1 = torch.full_like(t_grid, x_domain[1], requires_grad=requires_grad)\n    y0 = torch.full_like(t_grid, y_domain[0], requires_grad=requires_grad)\n    y1 = torch.full_like(t_grid, y_domain[1], requires_grad=requires_grad)\n\n    down    = (x_grid, y0,     t_grid)\n    up      = (x_grid, y1,     t_grid)\n    left    = (x0,     y_grid, t_grid)\n    right   = (x1,     y_grid, t_grid)\n\n    return down, up, left, right","metadata":{"id":"j4ScZDgu40Xw","execution":{"iopub.status.busy":"2023-11-29T23:53:46.465662Z","iopub.execute_input":"2023-11-29T23:53:46.465905Z","iopub.status.idle":"2023-11-29T23:53:46.476147Z","shell.execute_reply.started":"2023-11-29T23:53:46.465884Z","shell.execute_reply":"2023-11-29T23:53:46.475343Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"#### Interior basic","metadata":{}},{"cell_type":"code","source":"def get_interior_points(x_domain, y_domain, t_domain, n_points, device = torch.device(\"cpu\"), requires_grad=True):\n    x_raw = torch.linspace(x_domain[0], x_domain[1], steps=n_points, requires_grad=requires_grad)\n    y_raw = torch.linspace(y_domain[0], y_domain[1], steps=n_points, requires_grad=requires_grad)\n    t_raw = torch.linspace(t_domain[0], t_domain[1], steps=n_points, requires_grad=requires_grad)\n    grids = torch.meshgrid(x_raw, y_raw, t_raw, indexing=\"ij\")\n\n    x = grids[0].reshape(-1, 1).to(device)\n    y = grids[1].reshape(-1, 1).to(device)\n    t = grids[2].reshape(-1, 1).to(device)\n    return x, y, t","metadata":{"id":"EILfWcA3nX3O","execution":{"iopub.status.busy":"2023-11-29T23:53:46.537917Z","iopub.execute_input":"2023-11-29T23:53:46.538185Z","iopub.status.idle":"2023-11-29T23:53:46.544861Z","shell.execute_reply.started":"2023-11-29T23:53:46.538162Z","shell.execute_reply":"2023-11-29T23:53:46.544074Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"#### Interior based on bedside map","metadata":{}},{"cell_type":"code","source":"def get_interior_points_mesh(t_domain, n_points, device=torch.device(\"cpu\"), requires_grad=True):\n    x_raw, y_raw, z_raw = dump_points(MESH_FILENAME)\n    t_raw = torch.linspace(t_domain[0], t_domain[1], steps=n_points)\n    x_grid, t_grid = torch.meshgrid(x_raw, t_raw, indexing=\"ij\")\n    y_grid, _      = torch.meshgrid(y_raw, t_raw, indexing=\"ij\")\n    z_grid, _      = torch.meshgrid(z_raw, t_raw, indexing=\"ij\")\n    x = x_grid.reshape(-1, 1).to(device)\n    y = y_grid.reshape(-1, 1).to(device)\n    z = z_grid.reshape(-1, 1).to(device)\n    t = t_grid.reshape(-1, 1).to(device)\n    x.requires_grad = True\n    y.requires_grad = True\n    z.requires_grad = True\n    t.requires_grad = True\n    return x, y, z, t\n\n\ndef dump_points(filename):\n    mesh = meshio.avsucd.read(filename)\n    points = torch.tensor(mesh.points, dtype=torch.float32)\n    x,y,z = points.transpose(0,1)\n    #-> translate into [0,1]\n    min_x, min_y, min_z = torch.min(x), torch.min(y), torch.min(z)\n    max_x, max_y, max_z = torch.max(x), torch.max(y), torch.max(z)\n    x = (x - min_x) / (max_x - min_x)\n    y = (y - min_y) / (max_y - min_y)\n    z = (z - min_z) / (max_z - min_z)\n    return x,y,z\n\n\ndef mesh_from_tensors(x,y,z):\n    normalized_points = torch.stack((x, y, z), dim=1).tolist()\n    new_mesh = meshio.Mesh(points=normalized_points, cells=mesh.cells)\n    return new_mesh","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.562518Z","iopub.execute_input":"2023-11-29T23:53:46.563124Z","iopub.status.idle":"2023-11-29T23:53:46.573860Z","shell.execute_reply.started":"2023-11-29T23:53:46.563099Z","shell.execute_reply":"2023-11-29T23:53:46.572905Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"x_raw, y_raw, z_raw = dump_points(MESH_FILENAME)\nx_interior, y_interior, z_interior, t_interior = get_interior_points_mesh(t_domain, N_POINTS, device)\nx_domain = [x_interior.min().item(), x_interior.max().item()]\ny_domain = [y_interior.min().item(), y_interior.max().item()]\nX_POINTS = x_interior.size()[0] // N_POINTS\nY_POINTS = x_interior.size()[0] // N_POINTS\nLENGTH = x_domain[1]","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.601466Z","iopub.execute_input":"2023-11-29T23:53:46.601726Z","iopub.status.idle":"2023-11-29T23:53:46.611155Z","shell.execute_reply.started":"2023-11-29T23:53:46.601703Z","shell.execute_reply":"2023-11-29T23:53:46.610243Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"x_initial, y_initial, t_initial = get_initial_mesh(x_domain, y_domain, t_domain, N_POINTS, device)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.623652Z","iopub.execute_input":"2023-11-29T23:53:46.624097Z","iopub.status.idle":"2023-11-29T23:53:46.629007Z","shell.execute_reply.started":"2023-11-29T23:53:46.624073Z","shell.execute_reply":"2023-11-29T23:53:46.628157Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"down, up, left, right = get_boundary_points(x_domain, y_domain, t_domain, N_POINTS, device)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:53:46.660646Z","iopub.execute_input":"2023-11-29T23:53:46.661163Z","iopub.status.idle":"2023-11-29T23:53:46.665476Z","shell.execute_reply.started":"2023-11-29T23:53:46.661139Z","shell.execute_reply":"2023-11-29T23:53:46.664615Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"class Loss:\n    def __init__(\n        self,\n        x_domain: Tuple[float, float],\n        y_domain: Tuple[float, float],\n        t_domain: Tuple[float, float],\n        n_points: int,\n        initial_condition: Callable,\n        floor: Callable,\n        weight_r: float = 1.0,\n        weight_b: float = 1.0,\n        weight_i: float = 1.0,\n        verbose: bool = False,\n    ):\n        self.x_domain = x_domain\n        self.y_domain = y_domain\n        self.t_domain = t_domain\n        self.n_points = n_points\n        self.initial_condition = initial_condition\n        self.floor = floor\n        self.weight_r = weight_r\n        self.weight_b = weight_b\n        self.weight_i = weight_i\n\n    def residual_loss(self, pinn: PINN):\n        # x, y, t = get_interior_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n        x,y,z,t = x_interior, y_interior, z_interior, t_interior\n        u = f(pinn, x, y, t)\n\n        loss = dfdt(pinn, x, y, t, u, order=2) - \\\n                      GRAVITY * ((dfdx(pinn, x, y, t, u) - dzdx(x,y))*dfdx(pinn, x, y, t, u) + \\\n                      (u-z) * dfdx(pinn, x, y, t, u, order=2) + \\\n                      (dfdy(pinn, x, y, t, u) - dzdy(x,y))*dfdy(pinn, x, y, t, u) + \\\n                      (u-z) * dfdy(pinn, x, y, t, u, order=2))\n        \n        # loss = dfdt(pinn, x, y, t, u, order=2) - \\\n        #       GRAVITY * (dfdx(pinn, x, y, t, u) ** 2 + \\\n        #       (u-z) * dfdx(pinn, x, y, t, u, order=2) + \\\n        #       dfdy(pinn, x, y, t, u) ** 2 + \\\n        #       (u-z) * dfdy(pinn, x, y, t, u, order=2))\n        return loss.pow(2).mean()\n\n    def initial_loss(self, pinn: PINN):\n        x, y, t = x_initial, y_initial, t_initial #get_initial_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n        pinn_init = self.initial_condition(x, y)\n        loss = f(pinn, x, y, t) - pinn_init\n        return loss.pow(2).mean()\n\n    def boundary_loss(self, pinn: PINN):\n        # down, up, left, right = get_boundary_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n        x_down,  y_down,  t_down    = down\n        x_up,    y_up,    t_up      = up\n        x_left,  y_left,  t_left    = left\n        x_right, y_right, t_right   = right\n        \n        loss_down  = dfdy( pinn, x_down,  y_down,  t_down  )\n        loss_up    = dfdy( pinn, x_up,    y_up,    t_up    )\n        loss_left  = dfdx( pinn, x_left,  y_left,  t_left  )\n        loss_right = dfdx( pinn, x_right, y_right, t_right )\n\n        return loss_down.pow(2).mean()  + \\\n            loss_up.pow(2).mean()    + \\\n            loss_left.pow(2).mean()  + \\\n            loss_right.pow(2).mean()\n\n    def verbose(self, pinn: PINN, only_initial=False):\n        \"\"\"\n        Returns all parts of the loss function\n\n        Not used during training! Only for checking the results later.\n        \"\"\"\n        residual_loss = self.residual_loss(pinn)\n        initial_loss = self.initial_loss(pinn)\n        boundary_loss = self.boundary_loss(pinn)\n\n        final_loss = \\\n            self.weight_r * residual_loss + \\\n            self.weight_i * initial_loss + \\\n            self.weight_b * boundary_loss\n\n        if only_initial:\n          final_loss = \\\n            self.weight_r * residual_loss + \\\n            self.weight_i * initial_loss + \\\n            self.weight_b * boundary_loss # 5, 1000 i 1?, 0.0005\n\n        return final_loss, residual_loss, initial_loss, boundary_loss\n\n    def __call__(self, pinn: PINN, only_initial=False):\n        \"\"\"\n        Allows you to use the instance of this class as if it were a function:\n\n        ```\n            >>> loss = Loss(*some_args)\n            >>> calculated_loss = loss(pinn)\n        ```\n        \"\"\"\n        return self.verbose(pinn, only_initial)","metadata":{"id":"ncSFOeJ86jEC","execution":{"iopub.status.busy":"2023-11-29T23:53:46.684329Z","iopub.execute_input":"2023-11-29T23:53:46.684607Z","iopub.status.idle":"2023-11-29T23:53:46.702187Z","shell.execute_reply.started":"2023-11-29T23:53:46.684583Z","shell.execute_reply":"2023-11-29T23:53:46.701165Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## Train function","metadata":{"id":"R_EhvAmB-HsO"}},{"cell_type":"code","source":"def train_model(\n    nn_approximator: PINN,\n    loss_fn: Callable,\n    learning_rate: int = 0.01,\n    max_epochs: int = 1_000\n) -> PINN:\n\n    optimizer = torch.optim.Adam(nn_approximator.parameters(), lr=learning_rate)\n    loss_values = []\n    residual_loss_values = []\n    initial_loss_values = []\n    boundary_loss_values = []\n    top_loss = 100000000\n\n    for epoch in range(max_epochs):\n        try:\n            loss: torch.Tensor = loss_fn(nn_approximator)\n            optimizer.zero_grad()\n            loss[0].backward()\n#             torch.nn.utils.clip_grad_norm_(nn_approximator.parameters(), 0.5)\n            optimizer.step()\n\n            if loss[0].item() < top_loss:\n                torch.save(nn_approximator, f\"./best_{RUN_NUM}.pt\")\n                top_loss = loss[0].item()\n\n            loss_values.append(loss[0].item())\n            residual_loss_values.append(loss[1].item())\n            initial_loss_values.append(loss[2].item())\n            boundary_loss_values.append(loss[3].item())\n            if (epoch + 1) % 1000 == 0:\n                print(f\"Epoch: {epoch + 1} - Loss: {float(loss[0].item()):>7f}, Residual Loss: {float(loss[1].item()):>7f}, Initital Loss: {float(loss[2].item()):>7f}, Boundary Loss: {float(loss[3].item()):>7f}\")\n\n        except KeyboardInterrupt:\n            break\n\n    return nn_approximator, np.array(loss_values), np.array(residual_loss_values), np.array(initial_loss_values), np.array(boundary_loss_values)","metadata":{"id":"gO-8FhOHxFIz","execution":{"iopub.status.busy":"2023-11-29T23:53:46.738025Z","iopub.execute_input":"2023-11-29T23:53:46.738549Z","iopub.status.idle":"2023-11-29T23:53:46.747382Z","shell.execute_reply.started":"2023-11-29T23:53:46.738525Z","shell.execute_reply":"2023-11-29T23:53:46.746558Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"### Initial condition","metadata":{}},{"cell_type":"code","source":"def initial_condition(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n    r = torch.sqrt((x-LENGTH/2)**2 + (y-LENGTH/2)**2)\n    res = 2 * torch.exp(-(r)**2 * 30) + 2\n    return res","metadata":{"id":"10obIY3nZypX","execution":{"iopub.status.busy":"2023-11-29T23:53:46.792095Z","iopub.execute_input":"2023-11-29T23:53:46.792350Z","iopub.status.idle":"2023-11-29T23:53:46.797238Z","shell.execute_reply.started":"2023-11-29T23:53:46.792327Z","shell.execute_reply":"2023-11-29T23:53:46.796387Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"# Running code","metadata":{"id":"4y8UC4B2AR-X"}},{"cell_type":"markdown","source":"## Train data","metadata":{"id":"cydEKxCd-W-s"}},{"cell_type":"code","source":"pinn = PINN(LAYERS, NEURONS_PER_LAYER, act=nn.Tanh()).to(device)\n\n# train the PINN\nloss_fn = Loss(\n    x_domain=x_domain,\n    y_domain=y_domain,\n    t_domain=t_domain,\n    n_points=N_POINTS,\n    initial_condition=initial_condition,\n    floor=floor,\n    weight_r=WEIGHT_RESIDUAL,\n    weight_b=WEIGHT_BOUNDARY,\n    weight_i=WEIGHT_INITIAL\n)\n\npinn_trained, loss_values, residual_loss_values, initial_loss_values, boundary_loss_values = train_model(\n    pinn, loss_fn=loss_fn, learning_rate=LEARNING_RATE, max_epochs=EPOCHS)\n\nlosses = loss_fn.verbose(pinn)\n\nprint(f'Total loss: \\t{losses[0]:.5f} ({losses[0]:.3E})')\nprint(f'Interior loss: \\t{losses[1]:.5f} ({losses[1]:.3E})')\nprint(f'Initial loss: \\t{losses[2]:.5f} ({losses[2]:.3E})')\nprint(f'Boundary loss: \\t{losses[3]:.5f} ({losses[3]:.3E})')","metadata":{"id":"br0hz_u9xKy4","execution":{"iopub.status.busy":"2023-11-29T23:53:46.952220Z","iopub.execute_input":"2023-11-29T23:53:46.952729Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch: 1000 - Loss: 647.611816, Residual Loss: 12693.278320, Initital Loss: 4.315961, Boundary Loss: 0.000000\nEpoch: 2000 - Loss: 266.125061, Residual Loss: 5075.428711, Initital Loss: 4.117876, Boundary Loss: 0.000000\nEpoch: 3000 - Loss: 18224.353516, Residual Loss: 364251.562500, Initital Loss: 3.924970, Boundary Loss: 0.000000\nEpoch: 4000 - Loss: 117.984383, Residual Loss: 2135.487549, Initital Loss: 3.736670, Boundary Loss: 0.000000\nEpoch: 5000 - Loss: 74.008942, Residual Loss: 1266.965088, Initital Loss: 3.553561, Boundary Loss: 0.000000\nEpoch: 6000 - Loss: 46.938530, Residual Loss: 736.250488, Initital Loss: 3.375335, Boundary Loss: 0.000000\nEpoch: 7000 - Loss: 31.049908, Residual Loss: 428.882660, Initital Loss: 3.201924, Boundary Loss: 0.000000\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_running_average(loss_values, \"Loss function (runnig average)\", \"total_loss\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_running_average(residual_loss_values, \"Residual loss function (running average)\", \"residual_loss\")","metadata":{"id":"CWgn1DG6aM9U","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_running_average(initial_loss_values, \"Initial loss function (running average)\", \"initial_loss\")","metadata":{"id":"MndrmaIoaQLS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_running_average(boundary_loss_values, \"Boundary loss function (running average)\", \"boundary_loss\")","metadata":{"id":"LgB0f7lVaTQS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_intial_condition(x_domain=x_domain, \n                      y_domain=y_domain, \n                      t_domain=t_domain,\n                      pinn=pinn,\n                      initial_condition=initial_condition,\n                      n_points=N_POINTS_PLOT,\n                      length=LENGTH,\n                      floor=floor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_simulation_by_frame(total_time=TOTAL_TIME,\n                   x_domain=x_domain, \n                   y_domain=y_domain, \n                   t_domain=t_domain,\n                   pinn=pinn,\n                   n_points=N_POINTS_PLOT,\n                   length=LENGTH,\n                   floor=floor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_gif(TOTAL_TIME, title=f\"tsunami_{RUN_NUM}\")\ncreate_gif_2d(TOTAL_TIME, title=f\"tsunami_{RUN_NUM}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"date = datetime.now()\n\ncontext: ReportContext = {\n           'num': RUN_NUM,\n           'date': date,\n           'WEIGHT_RESIDUAL': WEIGHT_RESIDUAL, \n           'WEIGHT_INITIAL': WEIGHT_INITIAL, \n           'WEIGHT_BOUNDARY': WEIGHT_BOUNDARY,\n           'LAYERS': LAYERS, \n           'NEURONS_PER_LAYER': NEURONS_PER_LAYER,\n           'EPOCHS': EPOCHS, \n           'LEARNING_RATE': LEARNING_RATE,\n           'total_loss': f\"{losses[0]:.3E}\",\n           \"residual_loss\": f\"{losses[1]:.3E}\",\n           \"initial_loss\": f\"{losses[2]:.3E}\",\n           \"boundary_loss\": f\"{losses[3]:.3E}\",\n           \"img1\": \"./results/total_loss.png\",\n           \"img2\": \"./results/residual_loss.png\",\n           \"img3\": \"./results/initial_loss.png\",\n           \"img4\": \"./results/boundary_loss.png\",\n    }\n\ncreate_report(context,\n              env_path=\"/kaggle/\",\n              template_path=\"/input/report-template/report_template.html\",\n              report_title=f\"report_{RUN_NUM}.pdf\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # with profiling\n# global x_domain, y_domain, t_domain, loss_fn, pinn_trained, loss_values, residual_loss_values, initial_loss_values, boundary_loss_values, losses\n\n# def run_training():\n#     pinn = PINN(LAYERS, NEURONS_PER_LAYER, act=nn.Tanh()).to(device)\n    \n#     x_domain = [0.0, LENGTH]\n#     y_domain = [0.0, LENGTH]\n#     t_domain = [0.0, TOTAL_TIME]\n    \n#     # train the PINN\n#     loss_fn = Loss(\n#         x_domain=x_domain,\n#         y_domain=y_domain,\n#         t_domain=t_domain,\n#         n_points=N_POINTS,\n#         initial_condition=initial_condition,\n#         floor=floor,\n#         weight_r=WEIGHT_RESIDUAL,\n#         weight_b=WEIGHT_BOUNDARY,\n#         weight_i=WEIGHT_INITIAL\n#     )\n    \n#     pinn_trained, loss_values, residual_loss_values, initial_loss_values, boundary_loss_values = train_model(\n#         pinn, loss_fn=loss_fn, learning_rate=LEARNING_RATE, max_epochs=EPOCHS)\n    \n#     pinn = pinn.cpu()\n#     losses = loss_fn.verbose(pinn)\n#     print(f'Total loss: \\t{losses[0]:.5f} ({losses[0]:.3E})')\n#     print(f'Interior loss: \\t{losses[1]:.5f} ({losses[1]:.3E})')\n#     print(f'Initial loss: \\t{losses[2]:.5f} ({losses[2]:.3E})')\n#     print(f'Boundary loss: \\t{losses[3]:.5f} ({losses[3]:.3E})')\n\n# %prun -D program3.prof run_training()","metadata":{"execution":{"iopub.status.busy":"2023-11-29T21:21:21.577133Z","iopub.status.idle":"2023-11-29T21:21:21.577460Z","shell.execute_reply.started":"2023-11-29T21:21:21.577299Z","shell.execute_reply":"2023-11-29T21:21:21.577315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"model = torch.load(f\"kaggle/working/best_{RUN_NUM}.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-11-29T21:21:21.578329Z","iopub.status.idle":"2023-11-29T21:21:21.578660Z","shell.execute_reply.started":"2023-11-29T21:21:21.578474Z","shell.execute_reply":"2023-11-29T21:21:21.578488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_simulation_by_frame(total_time=TOTAL_TIME,\n                   x_domain=x_domain, \n                   y_domain=y_domain, \n                   t_domain=t_domain,\n                   pinn=model.to(device),\n                   n_points=N_POINTS_PLOT,\n                   length=LENGTH,\n                   floor=floor)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T21:21:21.580721Z","iopub.status.idle":"2023-11-29T21:21:21.581028Z","shell.execute_reply.started":"2023-11-29T21:21:21.580876Z","shell.execute_reply":"2023-11-29T21:21:21.580890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio\nimport jinja2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom datetime import datetime\nfrom matplotlib.animation import FuncAnimation\nfrom typing import List, TypedDict, Callable\nfrom xhtml2pdf import pisa\n\n\nclass ReportContext(TypedDict):\n    num: int\n    date: datetime\n    WEIGHT_RESIDUAL: float \n    WEIGHT_INITIAL: float \n    WEIGHT_BOUNDARY: float\n    LAYERS: int\n    NEURONS_PER_LAYER: int\n    EPOCHS: int \n    LEARNING_RATE: float\n    total_loss: float\n    residual_loss: float\n    initial_loss: float\n    boundary_loss: float\n    img1: str\n    img2: str\n    img3: str\n    img4: str\n\n\ndef create_report(context: ReportContext, \n                  env_path: str, \n                  template_path: str, \n                  report_title: str) -> None:\n    template_loader = jinja2.FileSystemLoader(env_path)\n    template_env = jinja2.Environment(loader=template_loader)\n\n    template = template_env.get_template(template_path)\n    output_text = template.render(context)\n    \n    with open(f'./results/{report_title}', \"w+b\") as out_pdf_file_handle:\n        pisa.CreatePDF(src=output_text, dest=out_pdf_file_handle)\n        \ndef create_gif_2d(total_time: float, \n               title: str, \n               step: float=0.01, \n               base_dir: str=\".\", \n               duration: float=0.1) -> None:\n    time_values = np.arange(0, total_time, step)\n    frames = []\n    for idx in range(len(time_values)):\n        image = imageio.v2.imread(base_dir + '/img/img_2d_{:03d}.png'.format(idx))\n        frames.append(image)\n\n    imageio.mimsave(f'{base_dir}/results/{title}.gif', frames, duration=duration)\n\ndef create_gif(total_time: float, \n               title: str, \n               step: float=0.01, \n               base_dir: str=\".\", \n               duration: float=0.1) -> None:\n    time_values = np.arange(0, total_time, step)\n    frames = []\n    for idx in range(len(time_values)):\n        image = imageio.v2.imread(base_dir + '/img/img_{:03d}.png'.format(idx))\n        frames.append(image)\n\n    imageio.mimsave(f'{base_dir}/results/{title}.gif', frames, duration=duration)\n\ndef plot_intial_condition(x_domain: List[float], \n                          y_domain: List[float], \n                          t_domain: List[float],\n                          length: float,\n                          pinn: 'PINN',\n                          initial_condition: Callable,\n                          floor: Callable,\n                          n_points: int) -> None:\n    title = \"Initial condition\"\n    \n    x, y, t = get_initial_points(x_domain, y_domain, t_domain, n_points, requires_grad=False)\n    z = initial_condition(x, y)\n    \n    fig = plot_color(z, x, y, n_points, n_points, f\"{title} - exact\")\n    fig = plot_3D(z, x, y, n_points, n_points, length, floor, f\"{title} - exact\")\n    \n    z = pinn(x, y, t)\n    \n    fig = plot_color(z, x, y, n_points, n_points, f\"{title} - PINN\")    \n    fig = plot_3D(z, x, y, n_points, n_points, length, floor, f\"{title} - PINN\")\n    \n\ndef plot_frame(x_domain: List[float], \n               y_domain: List[float], \n               t_domain: List[float], \n               pinn: 'PINN', \n               idx: int, \n               t_value: float, \n               n_points: int,\n               length: float,\n               floor: Callable,\n               base_dir: str=\".\") -> None:\n    x, y, _ = get_initial_points(x_domain, y_domain, t_domain, n_points, requires_grad=False)\n    t = torch.full_like(x, t_value)\n    z = pinn(x, y, t)\n    fig = plot_color(z, x, y, n_points, n_points, f\"PINN for t = {t_value}\")\n    plt.savefig(base_dir + '/img/img_2d_{:03d}.png'.format(idx))\n    fig = plot_3D(z, x, y, n_points, n_points, length, floor, f\"PINN for t = {t_value}\")\n    plt.savefig(base_dir + '/img/img_{:03d}.png'.format(idx))\n#     plt.clf()\n\n\ndef plot_simulation_by_frame(total_time: float, \n                             x_domain: List[float], \n                             y_domain: List[float], \n                             t_domain: List[float], \n                             pinn: 'PINN', \n                             n_points: int,\n                             length: float,\n                              floor: Callable,\n                             step:float=0.01) -> None:\n    time_values = np.arange(0, total_time, step)\n\n    for idx, t_value in enumerate(time_values):\n        plot_frame(x_domain=x_domain, \n                   y_domain=y_domain, \n                   t_domain=t_domain,\n                   pinn=pinn,\n                   idx=idx,\n                   t_value=t_value,\n                   n_points=n_points,\n                   length=length,\n                   floor=floor)\n\ndef running_average(y, window: int=100):\n    cumsum = np.cumsum(np.insert(y, 0, 0))\n    return (cumsum[window:] - cumsum[:-window]) / float(window)\n\ndef plot_running_average(loss_values, title: str, path: str):\n    average_loss = running_average(loss_values, window=100)\n    fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n    ax.set_title(title)\n    ax.set_xlabel(\"Epoch\")\n    ax.set_ylabel(\"Loss\")\n    ax.plot(average_loss)\n    ax.set_yscale('log')\n    \n    fig.savefig(f'./results/{path}.png')\n\ndef plot_solution(pinn: 'PINN', x: torch.Tensor, t: torch.Tensor, figsize=(8, 6), dpi=100):\n\n    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n    x_raw = torch.unique(x).reshape(-1, 1)\n    t_raw = torch.unique(t)\n\n    def animate(i):\n        if not i % 10 == 0:\n            t_partial = torch.ones_like(x_raw) * t_raw[i]\n            f_final = f(pinn, x_raw, t_partial)\n            ax.clear()\n            ax.plot(\n                x_raw.detach().numpy(), f_final.detach().numpy(), label=f\"Time {float(t[i])}\"\n            )\n            ax.set_ylim(-1, 1)\n            ax.legend()\n\n    n_frames = t_raw.shape[0]\n    return FuncAnimation(fig, animate, frames=n_frames, interval=100, repeat=False)\n\ndef plot_color(z: torch.Tensor, x: torch.Tensor, y: torch.Tensor, n_points_x, n_points_y, title, figsize=(8, 6), dpi=100, cmap=\"viridis\"):\n    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n    z_raw = z.detach().cpu().numpy()\n    x_raw = x.detach().cpu().numpy()\n    y_raw = y.detach().cpu().numpy()\n    X = x_raw.reshape(n_points_x, n_points_y)\n    Y = y_raw.reshape(n_points_x, n_points_y)\n    Z = z_raw.reshape(n_points_x, n_points_y)\n    ax.set_title(title)\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    c = ax.pcolormesh(X, Y, Z, cmap=cmap)\n    fig.colorbar(c, ax=ax)\n\n    return fig\n\ndef plot_3D(z: torch.Tensor, x: torch.Tensor, y: torch.Tensor, n_points_x, n_points_y, length: float, floor: torch.Tensor, title, figsize=(8, 6), dpi=100, limit=4):\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot(projection='3d')\n    z_raw = z.detach().cpu().numpy()\n    x_raw = x.detach().cpu().numpy()\n    y_raw = y.detach().cpu().numpy()\n    X = x_raw.reshape(n_points_x, n_points_y)\n    Y = y_raw.reshape(n_points_x, n_points_y)\n    Z = z_raw.reshape(n_points_x, n_points_y)\n    ax.set_title(title)\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.axes.set_zlim3d(bottom=0, top=limit)\n\n    c = ax.plot_surface(X, Y, Z)\n\n    # mesh\n    x_floor, y_floor, z_floor = dump_points(MESH_FILENAME)\n    ax.plot_trisurf(x_floor, y_floor, z_floor, linewidth=0.2)\n\n\n    # based on floor function\n    # x_floor = torch.linspace(0.0, length, floor_steps)\n    # y_floor = torch.linspace(0.0, length, floor_steps)\n    # z_floor = torch.zeros((floor_steps, 50))\n    # for x_idx, x_coord in enumerate(x_floor):\n    #     for y_idx, y_coord in enumerate(y_floor):\n    #         z_floor[x_idx, y_idx] = floor(x_coord, y_coord)\n    # x_floor = torch.tile(x_floor, (50, 1))\n    # y_floor = torch.tile(y_floor, (50, 1)).T\n    # f = ax.plot_surface(x_floor, y_floor, z_floor, color='green', alpha=0.7)\n    return fig","metadata":{"execution":{"iopub.status.busy":"2023-11-29T23:51:31.721193Z","iopub.execute_input":"2023-11-29T23:51:31.721576Z","iopub.status.idle":"2023-11-29T23:51:31.762464Z","shell.execute_reply.started":"2023-11-29T23:51:31.721547Z","shell.execute_reply":"2023-11-29T23:51:31.761563Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}