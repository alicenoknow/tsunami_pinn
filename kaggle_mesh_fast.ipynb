{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pawel Maczuga and Maciej Paszynski 2023\n",
    "\n",
    "import meshio\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from typing import Callable, Tuple, List\n",
    "# from utils import get_initial_points, plot_intial_condition, plot_simulation_by_frame, create_gif, ReportContext, create_report, plot_running_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T22:47:40.749235Z",
     "iopub.status.busy": "2023-11-29T22:47:40.748623Z",
     "iopub.status.idle": "2023-11-29T22:48:44.714246Z",
     "shell.execute_reply": "2023-11-29T22:48:44.712758Z",
     "shell.execute_reply.started": "2023-11-29T22:47:40.749206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting meshio\n",
      "  Downloading meshio-5.3.4-py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.7/167.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from meshio) (1.24.3)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from meshio) (13.5.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->meshio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->meshio) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->meshio) (0.1.0)\n",
      "Installing collected packages: meshio\n",
      "Successfully installed meshio-5.3.4\n",
      "Collecting xhtml2pdf\n",
      "  Obtaining dependency information for xhtml2pdf from https://files.pythonhosted.org/packages/1d/b7/637d96fe25024fdaaa4d265ae353cafdca706167325109fc1e574174b2bf/xhtml2pdf-0.2.13-py3-none-any.whl.metadata\n",
      "  Downloading xhtml2pdf-0.2.13-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting arabic-reshaper>=3.0.0 (from xhtml2pdf)\n",
      "  Downloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.10/site-packages (from xhtml2pdf) (1.1)\n",
      "Requirement already satisfied: Pillow>=8.1.1 in /opt/conda/lib/python3.10/site-packages (from xhtml2pdf) (10.1.0)\n",
      "Collecting pyHanko>=0.12.1 (from xhtml2pdf)\n",
      "  Obtaining dependency information for pyHanko>=0.12.1 from https://files.pythonhosted.org/packages/68/fc/d3d6dbb6ca6a9c755df5b6a1f2897e7560ef4c1384d8c89d182424f1582e/pyHanko-0.21.0-py3-none-any.whl.metadata\n",
      "  Downloading pyHanko-0.21.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting pyhanko-certvalidator>=0.19.5 (from xhtml2pdf)\n",
      "  Obtaining dependency information for pyhanko-certvalidator>=0.19.5 from https://files.pythonhosted.org/packages/12/72/9d5d45d5dee498003c9e4aceb0161f7d5e97cf7d2dc26f4802557fac39d6/pyhanko_certvalidator-0.26.2-py3-none-any.whl.metadata\n",
      "  Downloading pyhanko_certvalidator-0.26.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pypdf>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from xhtml2pdf) (3.17.0)\n",
      "Requirement already satisfied: python-bidi>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from xhtml2pdf) (0.4.2)\n",
      "Collecting reportlab[pycairo]>=4.0.4 (from xhtml2pdf)\n",
      "  Obtaining dependency information for reportlab[pycairo]>=4.0.4 from https://files.pythonhosted.org/packages/60/8b/fdd40ce4206bab7c8034f70925b8735c6fd57334d81e8aea9cfd0eb18603/reportlab-4.0.7-py3-none-any.whl.metadata\n",
      "  Downloading reportlab-4.0.7-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting svglib>=1.2.1 (from xhtml2pdf)\n",
      "  Downloading svglib-1.5.1.tar.gz (913 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.9/913.9 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->xhtml2pdf) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->xhtml2pdf) (0.5.1)\n",
      "Collecting asn1crypto>=1.5.1 (from pyHanko>=0.12.1->xhtml2pdf)\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting qrcode>=7.3.1 (from pyHanko>=0.12.1->xhtml2pdf)\n",
      "  Downloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tzlocal>=4.3 in /opt/conda/lib/python3.10/site-packages (from pyHanko>=0.12.1->xhtml2pdf) (5.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from pyHanko>=0.12.1->xhtml2pdf) (8.1.7)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from pyHanko>=0.12.1->xhtml2pdf) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /opt/conda/lib/python3.10/site-packages (from pyHanko>=0.12.1->xhtml2pdf) (6.0.1)\n",
      "Collecting cryptography>=41.0.5 (from pyHanko>=0.12.1->xhtml2pdf)\n",
      "  Obtaining dependency information for cryptography>=41.0.5 from https://files.pythonhosted.org/packages/62/bd/69628ab50368b1beb900eb1de5c46f8137169b75b2458affe95f2f470501/cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting oscrypto>=1.1.0 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf)\n",
      "  Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uritools>=3.0.1 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf)\n",
      "  Obtaining dependency information for uritools>=3.0.1 from https://files.pythonhosted.org/packages/6b/ff/b16f225ceeb47f5d8899371ce446a8d6c1fe509a8882998b869f2a794c25/uritools-4.0.2-py3-none-any.whl.metadata\n",
      "  Downloading uritools-4.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting rlPyCairo<1,>=0.2.0 (from reportlab[pycairo]>=4.0.4->xhtml2pdf)\n",
      "  Obtaining dependency information for rlPyCairo<1,>=0.2.0 from https://files.pythonhosted.org/packages/3d/d6/0f52d7f85e14429124651a3e4db8b50b1ec860b674648e34a8d5e0861771/rlPyCairo-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading rlPyCairo-0.3.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting freetype-py<2.4,>=2.3.0 (from reportlab[pycairo]>=4.0.4->xhtml2pdf)\n",
      "  Downloading freetype_py-2.3.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (978 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.9/978.9 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from svglib>=1.2.1->xhtml2pdf) (4.9.3)\n",
      "Requirement already satisfied: tinycss2>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from svglib>=1.2.1->xhtml2pdf) (1.2.1)\n",
      "Collecting cssselect2>=0.2.0 (from svglib>=1.2.1->xhtml2pdf)\n",
      "  Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf) (1.15.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qrcode>=7.3.1->pyHanko>=0.12.1->xhtml2pdf) (4.5.0)\n",
      "Collecting pypng (from qrcode>=7.3.1->pyHanko>=0.12.1->xhtml2pdf)\n",
      "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->pyHanko>=0.12.1->xhtml2pdf) (2023.7.22)\n",
      "Collecting pycairo>=1.20.0 (from rlPyCairo<1,>=0.2.0->reportlab[pycairo]>=4.0.4->xhtml2pdf)\n",
      "  Downloading pycairo-1.25.1.tar.gz (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.1/347.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf) (2.21)\n",
      "Downloading xhtml2pdf-0.2.13-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyHanko-0.21.0-py3-none-any.whl (433 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.2/433.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyhanko_certvalidator-0.26.2-py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rlPyCairo-0.3.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading uritools-4.0.2-py3-none-any.whl (10 kB)\n",
      "Downloading reportlab-4.0.7-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: svglib, pycairo\n",
      "  Building wheel for svglib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for svglib: filename=svglib-1.5.1-py3-none-any.whl size=30904 sha256=a272d2042601cc6f8cac1f4949fb2a012332aa81fe04bb6c0ceaab4c494ec825\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/9f/90/f37f4b9dbf82987a24ae14f15586e96715cb669a4710b3b85d\n",
      "  Building wheel for pycairo (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycairo: filename=pycairo-1.25.1-cp310-cp310-linux_x86_64.whl size=147893 sha256=155cf9176a51ff8b3ca5d6a7bef94c3fd860fc437e23173d2f6fa32aa36166c5\n",
      "  Stored in directory: /root/.cache/pip/wheels/d6/d8/c4/9bb1adbc349a349ed4718627f0afffeae26d9982060568cd30\n",
      "Successfully built svglib pycairo\n",
      "Installing collected packages: pypng, asn1crypto, arabic-reshaper, uritools, reportlab, qrcode, pycairo, oscrypto, freetype-py, rlPyCairo, cssselect2, cryptography, svglib, pyhanko-certvalidator, pyHanko, xhtml2pdf\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 41.0.3\n",
      "    Uninstalling cryptography-41.0.3:\n",
      "      Successfully uninstalled cryptography-41.0.3\n",
      "Successfully installed arabic-reshaper-3.0.0 asn1crypto-1.5.1 cryptography-41.0.7 cssselect2-0.7.0 freetype-py-2.3.0 oscrypto-1.3.0 pyHanko-0.21.0 pycairo-1.25.1 pyhanko-certvalidator-0.26.2 pypng-0.20220715.0 qrcode-7.4.2 reportlab-4.0.7 rlPyCairo-0.3.0 svglib-1.5.1 uritools-4.0.2 xhtml2pdf-0.2.13\n"
     ]
    }
   ],
   "source": [
    "!pip install meshio\n",
    "!pip install xhtml2pdf\n",
    "!mkdir img\n",
    "!mkdir results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESH_FILENAME = os.path.join(\"data\", \"val_square_UTM_translated_4.inp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NUM = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yRUNbvoDoDU9"
   },
   "outputs": [],
   "source": [
    "## LENGTH = 1. # Domain size in x axis. Always starts at 0\n",
    "TOTAL_TIME = 0.5 # Domain size in t axis. Always starts at 0\n",
    "N_POINTS = 15 # Number of in single asxis\n",
    "N_POINTS_PLOT = 100 # Number of points in single axis used in plotting\n",
    "\n",
    "WEIGHT_RESIDUAL = 0.05 # Weight of residual part of loss function\n",
    "WEIGHT_INITIAL = 3 # Weight of initial part of loss function\n",
    "WEIGHT_BOUNDARY = 0.0005 # Weight of boundary part of loss function\n",
    "\n",
    "# Original\n",
    "# WEIGHT_RESIDUAL = 0.03 # Weight of residual part of loss function\n",
    "# WEIGHT_INITIAL = 1.0 # Weight of initial part of loss function\n",
    "# WEIGHT_BOUNDARY = 0.0005 # Weight of boundary part of loss function\n",
    "\n",
    "LAYERS = 10\n",
    "NEURONS_PER_LAYER = 120\n",
    "EPOCHS = 50_000\n",
    "LEARNING_RATE = 0.00005\n",
    "GRAVITY = 9.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_domain = [0, TOTAL_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor(x, y):\n",
    "    \"\"\"Get the sea floor value\"\"\"\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3])\n"
     ]
    }
   ],
   "source": [
    "mesh = meshio.avsucd.read(MESH_FILENAME)\n",
    "vertices = torch.tensor(mesh.points, dtype=torch.float32)  # Tensor of vertices' coordinates\n",
    "triangles = mesh.cells_dict['triangle']  # Connectivity information for triangles as NumPy array\n",
    "\n",
    "print(vertices.shape)\n",
    "\n",
    "# Function to compute partial derivatives at vertices\n",
    "def compute_derivatives_at_vertices(vertices, triangles):\n",
    "    dx_vertices = torch.zeros(vertices.shape[0])  # Initialize tensors for derivatives\n",
    "    dy_vertices = torch.zeros(vertices.shape[0])\n",
    "\n",
    "    for triangle in triangles:\n",
    "        # Extract vertex indices for the current triangle\n",
    "        idx1, idx2, idx3 = triangle\n",
    "        \n",
    "        # Vertices' coordinates for the current triangle\n",
    "        v1, v2, v3 = vertices[idx1], vertices[idx2], vertices[idx3]\n",
    "        \n",
    "        # Compute partial derivatives (approximate gradient using cross product of edges)\n",
    "        dx = torch.cross(v2 - v1, v3 - v1)[0] / 2  # x-component of the cross product\n",
    "        dy = torch.cross(v2 - v1, v3 - v1)[1] / 2  # y-component of the cross product\n",
    "        \n",
    "        # Add computed derivatives to the corresponding vertices\n",
    "        dx_vertices[idx1] += dx\n",
    "        dx_vertices[idx2] += dx\n",
    "        dx_vertices[idx3] += dx\n",
    "        \n",
    "        dy_vertices[idx1] += dy\n",
    "        dy_vertices[idx2] += dy\n",
    "        dy_vertices[idx3] += dy\n",
    "\n",
    "    return dx_vertices.to(device), dy_vertices.to(device)\n",
    "\n",
    "# Compute derivatives at vertices\n",
    "dx_vertices, dy_vertices = compute_derivatives_at_vertices(vertices, triangles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iO0Bk6pp5-oz"
   },
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    \"\"\"Simple neural network accepting two features as input and returning a single output\n",
    "\n",
    "    In the context of PINNs, the neural network is used as universal function approximator\n",
    "    to approximate the solution of the differential equation\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden: int, dim_hidden: int, act=nn.Tanh()):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_in = nn.Linear(3, dim_hidden)\n",
    "        self.layer_out = nn.Linear(dim_hidden, 1)\n",
    "\n",
    "        num_middle = num_hidden - 1\n",
    "        self.middle_layers = nn.ModuleList(\n",
    "            [nn.Linear(dim_hidden, dim_hidden) for _ in range(num_middle)]\n",
    "        )\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        x_stack = torch.cat([x, y, t], dim=1).to(device)\n",
    "        out = self.act(self.layer_in(x_stack))\n",
    "        for layer in self.middle_layers:\n",
    "            out = self.act(layer(out))\n",
    "        logits = self.layer_out(out)\n",
    "        return logits\n",
    "\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "\n",
    "def f(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute the value of the approximate solution from the NN model\"\"\"\n",
    "    return pinn(x, y, t)\n",
    "\n",
    "\n",
    "def df(output: torch.Tensor, input: torch.Tensor, order: int = 1) -> torch.Tensor:\n",
    "    \"\"\"Compute neural network derivative with respect to input features using PyTorch autograd engine\"\"\"\n",
    "    df_value = output\n",
    "    for _ in range(order):\n",
    "        df_value = torch.autograd.grad(\n",
    "            df_value,\n",
    "            input,\n",
    "            grad_outputs=torch.ones_like(input),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "\n",
    "    return df_value\n",
    "\n",
    "\n",
    "def dfdt(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor, f_val=None, order: int = 1):\n",
    "    f_value = f_val if f_val is not None else f(pinn, x, y, t)\n",
    "    # f_value = f(pinn, x, y, t)\n",
    "    return df(f_value, t, order=order)\n",
    "\n",
    "\n",
    "def dfdx(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor, f_val=None, order: int = 1):\n",
    "    # f_value = f(pinn, x, y, t)\n",
    "    f_value = f_val if f_val is not None else f(pinn, x, y, t)\n",
    "    return df(f_value, x, order=order)\n",
    "\n",
    "def dfdy(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor, f_val=None, order: int = 1):\n",
    "    # f_value = f(pinn, x, y, t)\n",
    "    f_value = f_val if f_val is not None else f(pinn, x, y, t)\n",
    "    return df(f_value, y, order=order)\n",
    "\n",
    "def dzdx(x: torch.Tensor, y: torch.Tensor, order: int = 1):\n",
    "    return dx_vertices\n",
    "\n",
    "def dzdy(x: torch.Tensor, y: torch.Tensor, order: int = 1):\n",
    "    return dy_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPaX88HM6bTH"
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_points(x_domain: List[float], \n",
    "                       y_domain: List[float], \n",
    "                       t_domain: List[float], \n",
    "                       n_points: int, \n",
    "                       device=torch.device(\"cpu\"), \n",
    "                       requires_grad=True):\n",
    "    x_linspace = torch.linspace(x_domain[0], x_domain[1], n_points)\n",
    "    y_linspace = torch.linspace(y_domain[0], y_domain[1], n_points)\n",
    "    \n",
    "    x_grid, y_grid = torch.meshgrid(x_linspace, y_linspace, indexing=\"ij\")\n",
    "    \n",
    "    x_grid = x_grid.reshape(-1, 1).to(device)\n",
    "    y_grid = y_grid.reshape(-1, 1).to(device)\n",
    "    \n",
    "    x_grid.requires_grad = requires_grad\n",
    "    y_grid.requires_grad = requires_grad\n",
    "    \n",
    "    t0 = torch.full_like(x_grid, t_domain[0], requires_grad=requires_grad)\n",
    "    return (x_grid, y_grid, t0)\n",
    "\n",
    "def get_initial_mesh(x_domain: List[float], \n",
    "                       y_domain: List[float], \n",
    "                       t_domain: List[float], \n",
    "                       n_points: int, \n",
    "                       device=torch.device(\"cpu\"), \n",
    "                       requires_grad=True):\n",
    "    x_raw, y_raw, _ = dump_points(MESH_FILENAME)\n",
    "    x = x_raw.to(device)\n",
    "    y = y_raw.to(device)\n",
    "    \n",
    "    x.requires_grad = requires_grad\n",
    "    y.requires_grad = requires_grad\n",
    "\n",
    "    x = x.reshape(-1, 1).to(device)\n",
    "    y = y.reshape(-1, 1).to(device)\n",
    "    \n",
    "    t0 = torch.full_like(x, t_domain[0], requires_grad=requires_grad)\n",
    "    return (x, y, t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "j4ScZDgu40Xw"
   },
   "outputs": [],
   "source": [
    "def get_boundary_points(x_domain, y_domain, t_domain, n_points, device = torch.device(\"cpu\"), requires_grad=True):\n",
    "    \"\"\"\n",
    "         .+------+\n",
    "       .' |    .'|\n",
    "      +---+--+'  |\n",
    "      |   |  |   |\n",
    "    y |  ,+--+---+\n",
    "      |.'    | .' t\n",
    "      +------+'\n",
    "         x\n",
    "    \"\"\"\n",
    "    x_linspace = torch.linspace(x_domain[0], x_domain[1], n_points)\n",
    "    y_linspace = torch.linspace(y_domain[0], y_domain[1], n_points)\n",
    "    t_linspace = torch.linspace(t_domain[0], t_domain[1], n_points)\n",
    "\n",
    "    x_grid, t_grid = torch.meshgrid(x_linspace, t_linspace, indexing=\"ij\")\n",
    "    y_grid, _      = torch.meshgrid(y_linspace, t_linspace, indexing=\"ij\")\n",
    "\n",
    "    x_grid = x_grid.reshape(-1, 1).to(device)\n",
    "    y_grid = y_grid.reshape(-1, 1).to(device)\n",
    "    t_grid = t_grid.reshape(-1, 1).to(device)\n",
    "    \n",
    "    x_grid.requires_grad = requires_grad\n",
    "    y_grid.requires_grad = requires_grad\n",
    "    t_grid.requires_grad = requires_grad\n",
    "\n",
    "    x0 = torch.full_like(t_grid, x_domain[0], requires_grad=requires_grad)\n",
    "    x1 = torch.full_like(t_grid, x_domain[1], requires_grad=requires_grad)\n",
    "    y0 = torch.full_like(t_grid, y_domain[0], requires_grad=requires_grad)\n",
    "    y1 = torch.full_like(t_grid, y_domain[1], requires_grad=requires_grad)\n",
    "\n",
    "    down    = (x_grid, y0,     t_grid)\n",
    "    up      = (x_grid, y1,     t_grid)\n",
    "    left    = (x0,     y_grid, t_grid)\n",
    "    right   = (x1,     y_grid, t_grid)\n",
    "\n",
    "    return down, up, left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interior basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EILfWcA3nX3O"
   },
   "outputs": [],
   "source": [
    "def get_interior_points(x_domain, y_domain, t_domain, n_points, device = torch.device(\"cpu\"), requires_grad=True):\n",
    "    x_raw = torch.linspace(x_domain[0], x_domain[1], steps=n_points, requires_grad=requires_grad)\n",
    "    y_raw = torch.linspace(y_domain[0], y_domain[1], steps=n_points, requires_grad=requires_grad)\n",
    "    t_raw = torch.linspace(t_domain[0], t_domain[1], steps=n_points, requires_grad=requires_grad)\n",
    "    grids = torch.meshgrid(x_raw, y_raw, t_raw, indexing=\"ij\")\n",
    "\n",
    "    x = grids[0].reshape(-1, 1).to(device)\n",
    "    y = grids[1].reshape(-1, 1).to(device)\n",
    "    t = grids[2].reshape(-1, 1).to(device)\n",
    "    return x, y, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interior based on bedside map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interior_points_mesh(t_domain, n_points, device=torch.device(\"cpu\"), requires_grad=True):\n",
    "    x_raw, y_raw, z_raw = dump_points(MESH_FILENAME)\n",
    "    t_raw = torch.linspace(t_domain[0], t_domain[1], steps=n_points)\n",
    "    x_grid, t_grid = torch.meshgrid(x_raw, t_raw, indexing=\"ij\")\n",
    "    y_grid, _      = torch.meshgrid(y_raw, t_raw, indexing=\"ij\")\n",
    "    z_grid, _      = torch.meshgrid(z_raw, t_raw, indexing=\"ij\")\n",
    "    x = x_grid.reshape(-1, 1).to(device)\n",
    "    y = y_grid.reshape(-1, 1).to(device)\n",
    "    z = z_grid.reshape(-1, 1).to(device)\n",
    "    t = t_grid.reshape(-1, 1).to(device)\n",
    "    x.requires_grad = True\n",
    "    y.requires_grad = True\n",
    "    z.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "    return x, y, z, t\n",
    "\n",
    "\n",
    "def dump_points(filename):\n",
    "    mesh = meshio.avsucd.read(filename)\n",
    "    points = torch.tensor(mesh.points, dtype=torch.float32)\n",
    "    x,y,z = points.transpose(0,1)\n",
    "    #-> translate into [0,1]\n",
    "    min_x, min_y, min_z = torch.min(x), torch.min(y), torch.min(z)\n",
    "    max_x, max_y, max_z = torch.max(x), torch.max(y), torch.max(z)\n",
    "    x = (x - min_x) / (max_x - min_x)\n",
    "    y = (y - min_y) / (max_y - min_y)\n",
    "    z = (z - min_z) / (max_z - min_z)\n",
    "    return x,y,z\n",
    "\n",
    "\n",
    "def mesh_from_tensors(x,y,z):\n",
    "    normalized_points = torch.stack((x, y, z), dim=1).tolist()\n",
    "    new_mesh = meshio.Mesh(points=normalized_points, cells=mesh.cells)\n",
    "    return new_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw, y_raw, z_raw = dump_points(MESH_FILENAME)\n",
    "x_interior, y_interior, z_interior, t_interior = get_interior_points_mesh(t_domain, N_POINTS, device)\n",
    "x_domain = [x_interior.min().item(), x_interior.max().item()]\n",
    "y_domain = [y_interior.min().item(), y_interior.max().item()]\n",
    "X_POINTS = x_interior.size()[0] // N_POINTS\n",
    "Y_POINTS = x_interior.size()[0] // N_POINTS\n",
    "LENGTH = x_domain[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_initial, y_initial, t_initial = get_initial_mesh(x_domain, y_domain, t_domain, N_POINTS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "down, up, left, right = get_boundary_points(x_domain, y_domain, t_domain, N_POINTS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ncSFOeJ86jEC"
   },
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_domain: Tuple[float, float],\n",
    "        y_domain: Tuple[float, float],\n",
    "        t_domain: Tuple[float, float],\n",
    "        n_points: int,\n",
    "        initial_condition: Callable,\n",
    "        floor: Callable,\n",
    "        weight_r: float = 1.0,\n",
    "        weight_b: float = 1.0,\n",
    "        weight_i: float = 1.0,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "        self.x_domain = x_domain\n",
    "        self.y_domain = y_domain\n",
    "        self.t_domain = t_domain\n",
    "        self.n_points = n_points\n",
    "        self.initial_condition = initial_condition\n",
    "        self.floor = floor\n",
    "        self.weight_r = weight_r\n",
    "        self.weight_b = weight_b\n",
    "        self.weight_i = weight_i\n",
    "\n",
    "    def residual_loss(self, pinn: PINN):\n",
    "        # x, y, t = get_interior_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n",
    "        x,y,z,t = x_interior, y_interior, z_interior, t_interior\n",
    "        u = f(pinn, x, y, t)\n",
    "\n",
    "        # loss = dfdt(pinn, x, y, t, u, order=2) - \\\n",
    "        #               GRAVITY * ((dfdx(pinn, x, y, t, u) - dzdx(x,y))*dfdx(pinn, x, y, t, u) + \\\n",
    "        #               (u-z) * dfdx(pinn, x, y, t, u, order=2) + \\\n",
    "        #               (dfdy(pinn, x, y, t, u) - dzdy(x,y))*dfdy(pinn, x, y, t, u) + \\\n",
    "        #               (u-z) * dfdy(pinn, x, y, t, u, order=2))\n",
    "        \n",
    "        loss = dfdt(pinn, x, y, t, u, order=2) - \\\n",
    "              GRAVITY * (dfdx(pinn, x, y, t, u) ** 2 + \\\n",
    "              (u-z) * dfdx(pinn, x, y, t, u, order=2) + \\\n",
    "              dfdy(pinn, x, y, t, u) ** 2 + \\\n",
    "              (u-z) * dfdy(pinn, x, y, t, u, order=2))\n",
    "        return loss.pow(2).mean()\n",
    "\n",
    "    def initial_loss(self, pinn: PINN):\n",
    "        x, y, t = x_initial, y_initial, t_initial #get_initial_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n",
    "        pinn_init = self.initial_condition(x, y)\n",
    "        loss = f(pinn, x, y, t) - pinn_init\n",
    "        return loss.pow(2).mean()\n",
    "\n",
    "    def boundary_loss(self, pinn: PINN):\n",
    "        # down, up, left, right = get_boundary_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n",
    "        x_down,  y_down,  t_down    = down\n",
    "        x_up,    y_up,    t_up      = up\n",
    "        x_left,  y_left,  t_left    = left\n",
    "        x_right, y_right, t_right   = right\n",
    "        \n",
    "        loss_down  = dfdy( pinn, x_down,  y_down,  t_down  )\n",
    "        loss_up    = dfdy( pinn, x_up,    y_up,    t_up    )\n",
    "        loss_left  = dfdx( pinn, x_left,  y_left,  t_left  )\n",
    "        loss_right = dfdx( pinn, x_right, y_right, t_right )\n",
    "\n",
    "        return loss_down.pow(2).mean()  + \\\n",
    "            loss_up.pow(2).mean()    + \\\n",
    "            loss_left.pow(2).mean()  + \\\n",
    "            loss_right.pow(2).mean()\n",
    "\n",
    "    def verbose(self, pinn: PINN, only_initial=False):\n",
    "        \"\"\"\n",
    "        Returns all parts of the loss function\n",
    "\n",
    "        Not used during training! Only for checking the results later.\n",
    "        \"\"\"\n",
    "        residual_loss = self.residual_loss(pinn)\n",
    "        initial_loss = self.initial_loss(pinn)\n",
    "        boundary_loss = self.boundary_loss(pinn)\n",
    "\n",
    "        final_loss = \\\n",
    "            self.weight_r * residual_loss + \\\n",
    "            self.weight_i * initial_loss + \\\n",
    "            self.weight_b * boundary_loss\n",
    "\n",
    "        if only_initial:\n",
    "          final_loss = \\\n",
    "            self.weight_r * residual_loss + \\\n",
    "            self.weight_i * initial_loss + \\\n",
    "            self.weight_b * boundary_loss # 5, 1000 i 1?, 0.0005\n",
    "\n",
    "        return final_loss, residual_loss, initial_loss, boundary_loss\n",
    "\n",
    "    def __call__(self, pinn: PINN, only_initial=False):\n",
    "        \"\"\"\n",
    "        Allows you to use the instance of this class as if it were a function:\n",
    "\n",
    "        ```\n",
    "            >>> loss = Loss(*some_args)\n",
    "            >>> calculated_loss = loss(pinn)\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return self.verbose(pinn, only_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_EhvAmB-HsO"
   },
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gO-8FhOHxFIz"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    nn_approximator: PINN,\n",
    "    loss_fn: Callable,\n",
    "    learning_rate: int = 0.01,\n",
    "    max_epochs: int = 1_000\n",
    ") -> PINN:\n",
    "\n",
    "    optimizer = torch.optim.Adam(nn_approximator.parameters(), lr=learning_rate)\n",
    "    loss_values = []\n",
    "    residual_loss_values = []\n",
    "    initial_loss_values = []\n",
    "    boundary_loss_values = []\n",
    "    top_loss = 100000000\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        try:\n",
    "            loss: torch.Tensor = loss_fn(nn_approximator)\n",
    "            optimizer.zero_grad()\n",
    "            loss[0].backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(nn_approximator.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "            if loss[0].item() < top_loss:\n",
    "                torch.save(nn_approximator, f\"./best_{RUN_NUM}.pt\")\n",
    "                top_loss = loss[0].item()\n",
    "\n",
    "            loss_values.append(loss[0].item())\n",
    "            residual_loss_values.append(loss[1].item())\n",
    "            initial_loss_values.append(loss[2].item())\n",
    "            boundary_loss_values.append(loss[3].item())\n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                print(f\"Epoch: {epoch + 1} - Loss: {float(loss[0].item()):>7f}, Residual Loss: {float(loss[1].item()):>7f}, Initital Loss: {float(loss[2].item()):>7f}, Boundary Loss: {float(loss[3].item()):>7f}\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "\n",
    "    return nn_approximator, np.array(loss_values), np.array(residual_loss_values), np.array(initial_loss_values), np.array(boundary_loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "10obIY3nZypX"
   },
   "outputs": [],
   "source": [
    "def initial_condition(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    r = torch.sqrt((x-LENGTH/2)**2 + (y-LENGTH/2)**2)\n",
    "    res = 2 * torch.exp(-(r)**2 * 30) + 2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4y8UC4B2AR-X"
   },
   "source": [
    "# Running code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cydEKxCd-W-s"
   },
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "br0hz_u9xKy4"
   },
   "outputs": [],
   "source": [
    "pinn = PINN(LAYERS, NEURONS_PER_LAYER, act=nn.Tanh()).to(device)\n",
    "\n",
    "# train the PINN\n",
    "loss_fn = Loss(\n",
    "    x_domain=x_domain,\n",
    "    y_domain=y_domain,\n",
    "    t_domain=t_domain,\n",
    "    n_points=N_POINTS,\n",
    "    initial_condition=initial_condition,\n",
    "    floor=floor,\n",
    "    weight_r=WEIGHT_RESIDUAL,\n",
    "    weight_b=WEIGHT_BOUNDARY,\n",
    "    weight_i=WEIGHT_INITIAL\n",
    ")\n",
    "\n",
    "pinn_trained, loss_values, residual_loss_values, initial_loss_values, boundary_loss_values = train_model(\n",
    "    pinn, loss_fn=loss_fn, learning_rate=LEARNING_RATE, max_epochs=EPOCHS)\n",
    "\n",
    "losses = loss_fn.verbose(pinn)\n",
    "\n",
    "print(f'Total loss: \\t{losses[0]:.5f} ({losses[0]:.3E})')\n",
    "print(f'Interior loss: \\t{losses[1]:.5f} ({losses[1]:.3E})')\n",
    "print(f'Initial loss: \\t{losses[2]:.5f} ({losses[2]:.3E})')\n",
    "print(f'Boundary loss: \\t{losses[3]:.5f} ({losses[3]:.3E})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_running_average(loss_values, \"Loss function (runnig average)\", \"total_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWgn1DG6aM9U"
   },
   "outputs": [],
   "source": [
    "plot_running_average(residual_loss_values, \"Residual loss function (running average)\", \"residual_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MndrmaIoaQLS"
   },
   "outputs": [],
   "source": [
    "plot_running_average(initial_loss_values, \"Initial loss function (running average)\", \"initial_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgB0f7lVaTQS"
   },
   "outputs": [],
   "source": [
    "plot_running_average(boundary_loss_values, \"Boundary loss function (running average)\", \"boundary_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intial_condition(x_domain=x_domain, \n",
    "                      y_domain=y_domain, \n",
    "                      t_domain=t_domain,\n",
    "                      pinn=pinn,\n",
    "                      initial_condition=initial_condition,\n",
    "                      n_points=N_POINTS_PLOT,\n",
    "                      length=LENGTH,\n",
    "                      floor=floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation_by_frame(total_time=TOTAL_TIME,\n",
    "                   x_domain=x_domain, \n",
    "                   y_domain=y_domain, \n",
    "                   t_domain=t_domain,\n",
    "                   pinn=pinn,\n",
    "                   n_points=N_POINTS_PLOT,\n",
    "                   length=LENGTH,\n",
    "                   floor=floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gif(TOTAL_TIME, title=f\"tsunami_{RUN_NUM}\")\n",
    "create_gif_2d(TOTAL_TIME, title=f\"tsunami_2d_{RUN_NUM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now()\n",
    "\n",
    "context: ReportContext = {\n",
    "           'num': RUN_NUM,\n",
    "           'date': date,\n",
    "           'WEIGHT_RESIDUAL': WEIGHT_RESIDUAL, \n",
    "           'WEIGHT_INITIAL': WEIGHT_INITIAL, \n",
    "           'WEIGHT_BOUNDARY': WEIGHT_BOUNDARY,\n",
    "           'LAYERS': LAYERS, \n",
    "           'NEURONS_PER_LAYER': NEURONS_PER_LAYER,\n",
    "           'EPOCHS': EPOCHS, \n",
    "           'LEARNING_RATE': LEARNING_RATE,\n",
    "           'total_loss': f\"{losses[0]:.3E}\",\n",
    "           \"residual_loss\": f\"{losses[1]:.3E}\",\n",
    "           \"initial_loss\": f\"{losses[2]:.3E}\",\n",
    "           \"boundary_loss\": f\"{losses[3]:.3E}\",\n",
    "           \"img1\": \"./results/total_loss.png\",\n",
    "           \"img2\": \"./results/residual_loss.png\",\n",
    "           \"img3\": \"./results/initial_loss.png\",\n",
    "           \"img4\": \"./results/boundary_loss.png\",\n",
    "    }\n",
    "\n",
    "create_report(context,\n",
    "              env_path=\"/kaggle/\",\n",
    "              template_path=\"/input/report-template/report_template.html\",\n",
    "              report_title=f\"report_{RUN_NUM}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T21:21:21.577133Z",
     "iopub.status.idle": "2023-11-29T21:21:21.577460Z",
     "shell.execute_reply": "2023-11-29T21:21:21.577315Z",
     "shell.execute_reply.started": "2023-11-29T21:21:21.577299Z"
    }
   },
   "outputs": [],
   "source": [
    "# # with profiling\n",
    "# global x_domain, y_domain, t_domain, loss_fn, pinn_trained, loss_values, residual_loss_values, initial_loss_values, boundary_loss_values, losses\n",
    "\n",
    "# def run_training():\n",
    "#     pinn = PINN(LAYERS, NEURONS_PER_LAYER, act=nn.Tanh()).to(device)\n",
    "    \n",
    "#     x_domain = [0.0, LENGTH]\n",
    "#     y_domain = [0.0, LENGTH]\n",
    "#     t_domain = [0.0, TOTAL_TIME]\n",
    "    \n",
    "#     # train the PINN\n",
    "#     loss_fn = Loss(\n",
    "#         x_domain=x_domain,\n",
    "#         y_domain=y_domain,\n",
    "#         t_domain=t_domain,\n",
    "#         n_points=N_POINTS,\n",
    "#         initial_condition=initial_condition,\n",
    "#         floor=floor,\n",
    "#         weight_r=WEIGHT_RESIDUAL,\n",
    "#         weight_b=WEIGHT_BOUNDARY,\n",
    "#         weight_i=WEIGHT_INITIAL\n",
    "#     )\n",
    "    \n",
    "#     pinn_trained, loss_values, residual_loss_values, initial_loss_values, boundary_loss_values = train_model(\n",
    "#         pinn, loss_fn=loss_fn, learning_rate=LEARNING_RATE, max_epochs=EPOCHS)\n",
    "    \n",
    "#     pinn = pinn.cpu()\n",
    "#     losses = loss_fn.verbose(pinn)\n",
    "#     print(f'Total loss: \\t{losses[0]:.5f} ({losses[0]:.3E})')\n",
    "#     print(f'Interior loss: \\t{losses[1]:.5f} ({losses[1]:.3E})')\n",
    "#     print(f'Initial loss: \\t{losses[2]:.5f} ({losses[2]:.3E})')\n",
    "#     print(f'Boundary loss: \\t{losses[3]:.5f} ({losses[3]:.3E})')\n",
    "\n",
    "# %prun -D program3.prof run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T21:21:21.578329Z",
     "iopub.status.idle": "2023-11-29T21:21:21.578660Z",
     "shell.execute_reply": "2023-11-29T21:21:21.578488Z",
     "shell.execute_reply.started": "2023-11-29T21:21:21.578474Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load(f\"kaggle/working/best_{RUN_NUM}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T21:21:21.580721Z",
     "iopub.status.idle": "2023-11-29T21:21:21.581028Z",
     "shell.execute_reply": "2023-11-29T21:21:21.580890Z",
     "shell.execute_reply.started": "2023-11-29T21:21:21.580876Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_simulation_by_frame(total_time=TOTAL_TIME,\n",
    "                   x_domain=x_domain, \n",
    "                   y_domain=y_domain, \n",
    "                   t_domain=t_domain,\n",
    "                   pinn=model.to(device),\n",
    "                   n_points=N_POINTS_PLOT,\n",
    "                   length=LENGTH,\n",
    "                   floor=floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import jinja2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from typing import List, TypedDict, Callable\n",
    "from xhtml2pdf import pisa\n",
    "\n",
    "\n",
    "class ReportContext(TypedDict):\n",
    "    num: int\n",
    "    date: datetime\n",
    "    WEIGHT_RESIDUAL: float \n",
    "    WEIGHT_INITIAL: float \n",
    "    WEIGHT_BOUNDARY: float\n",
    "    LAYERS: int\n",
    "    NEURONS_PER_LAYER: int\n",
    "    EPOCHS: int \n",
    "    LEARNING_RATE: float\n",
    "    total_loss: float\n",
    "    residual_loss: float\n",
    "    initial_loss: float\n",
    "    boundary_loss: float\n",
    "    img1: str\n",
    "    img2: str\n",
    "    img3: str\n",
    "    img4: str\n",
    "\n",
    "\n",
    "def create_report(context: ReportContext, \n",
    "                  env_path: str, \n",
    "                  template_path: str, \n",
    "                  report_title: str) -> None:\n",
    "    template_loader = jinja2.FileSystemLoader(env_path)\n",
    "    template_env = jinja2.Environment(loader=template_loader)\n",
    "\n",
    "    template = template_env.get_template(template_path)\n",
    "    output_text = template.render(context)\n",
    "    \n",
    "    with open(f'./results/{report_title}', \"w+b\") as out_pdf_file_handle:\n",
    "        pisa.CreatePDF(src=output_text, dest=out_pdf_file_handle)\n",
    "        \n",
    "def create_gif_2d(total_time: float, \n",
    "               title: str, \n",
    "               step: float=0.01, \n",
    "               base_dir: str=\".\", \n",
    "               duration: float=0.1) -> None:\n",
    "    time_values = np.arange(0, total_time, step)\n",
    "    frames = []\n",
    "    for idx in range(len(time_values)):\n",
    "        image = imageio.v2.imread(base_dir + '/img/img_2d_{:03d}.png'.format(idx))\n",
    "        frames.append(image)\n",
    "\n",
    "    imageio.mimsave(f'{base_dir}/results/{title}.gif', frames, duration=duration)\n",
    "\n",
    "def create_gif(total_time: float, \n",
    "               title: str, \n",
    "               step: float=0.01, \n",
    "               base_dir: str=\".\", \n",
    "               duration: float=0.1) -> None:\n",
    "    time_values = np.arange(0, total_time, step)\n",
    "    frames = []\n",
    "    for idx in range(len(time_values)):\n",
    "        image = imageio.v2.imread(base_dir + '/img/img_{:03d}.png'.format(idx))\n",
    "        frames.append(image)\n",
    "\n",
    "    imageio.mimsave(f'{base_dir}/results/{title}.gif', frames, duration=duration)\n",
    "\n",
    "def plot_intial_condition(x_domain: List[float], \n",
    "                          y_domain: List[float], \n",
    "                          t_domain: List[float],\n",
    "                          length: float,\n",
    "                          pinn: 'PINN',\n",
    "                          initial_condition: Callable,\n",
    "                          floor: Callable,\n",
    "                          n_points: int) -> None:\n",
    "    title = \"Initial condition\"\n",
    "    \n",
    "    x, y, t = get_initial_points(x_domain, y_domain, t_domain, n_points, requires_grad=False)\n",
    "    z = initial_condition(x, y)\n",
    "    \n",
    "    fig = plot_color(z, x, y, n_points, n_points, f\"{title} - exact\")\n",
    "    fig = plot_3D(z, x, y, n_points, n_points, length, floor, f\"{title} - exact\")\n",
    "    \n",
    "    z = pinn(x, y, t)\n",
    "    \n",
    "    fig = plot_color(z, x, y, n_points, n_points, f\"{title} - PINN\")    \n",
    "    fig = plot_3D(z, x, y, n_points, n_points, length, floor, f\"{title} - PINN\")\n",
    "    \n",
    "\n",
    "def plot_frame(x_domain: List[float], \n",
    "               y_domain: List[float], \n",
    "               t_domain: List[float], \n",
    "               pinn: 'PINN', \n",
    "               idx: int, \n",
    "               t_value: float, \n",
    "               n_points: int,\n",
    "               length: float,\n",
    "               floor: Callable,\n",
    "               base_dir: str=\".\") -> None:\n",
    "    x, y, _ = get_initial_points(x_domain, y_domain, t_domain, n_points, requires_grad=False)\n",
    "    t = torch.full_like(x, t_value)\n",
    "    z = pinn(x, y, t)\n",
    "    fig = plot_color(z, x, y, n_points, n_points, f\"PINN for t = {t_value}\")\n",
    "    plt.savefig(base_dir + '/img/img_2d_{:03d}.png'.format(idx))\n",
    "    fig = plot_3D(z, x, y, n_points, n_points, length, floor, f\"PINN for t = {t_value}\")\n",
    "    plt.savefig(base_dir + '/img/img_{:03d}.png'.format(idx))\n",
    "#     plt.clf()\n",
    "\n",
    "\n",
    "def plot_simulation_by_frame(total_time: float, \n",
    "                             x_domain: List[float], \n",
    "                             y_domain: List[float], \n",
    "                             t_domain: List[float], \n",
    "                             pinn: 'PINN', \n",
    "                             n_points: int,\n",
    "                             length: float,\n",
    "                              floor: Callable,\n",
    "                             step:float=0.01) -> None:\n",
    "    time_values = np.arange(0, total_time, step)\n",
    "\n",
    "    for idx, t_value in enumerate(time_values):\n",
    "        plot_frame(x_domain=x_domain, \n",
    "                   y_domain=y_domain, \n",
    "                   t_domain=t_domain,\n",
    "                   pinn=pinn,\n",
    "                   idx=idx,\n",
    "                   t_value=t_value,\n",
    "                   n_points=n_points,\n",
    "                   length=length,\n",
    "                   floor=floor)\n",
    "\n",
    "def running_average(y, window: int=100):\n",
    "    cumsum = np.cumsum(np.insert(y, 0, 0))\n",
    "    return (cumsum[window:] - cumsum[:-window]) / float(window)\n",
    "\n",
    "def plot_running_average(loss_values, title: str, path: str):\n",
    "    average_loss = running_average(loss_values, window=100)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.plot(average_loss)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    fig.savefig(f'./results/{path}.png')\n",
    "\n",
    "def plot_solution(pinn: 'PINN', x: torch.Tensor, t: torch.Tensor, figsize=(8, 6), dpi=100):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    x_raw = torch.unique(x).reshape(-1, 1)\n",
    "    t_raw = torch.unique(t)\n",
    "\n",
    "    def animate(i):\n",
    "        if not i % 10 == 0:\n",
    "            t_partial = torch.ones_like(x_raw) * t_raw[i]\n",
    "            f_final = f(pinn, x_raw, t_partial)\n",
    "            ax.clear()\n",
    "            ax.plot(\n",
    "                x_raw.detach().numpy(), f_final.detach().numpy(), label=f\"Time {float(t[i])}\"\n",
    "            )\n",
    "            ax.set_ylim(-1, 1)\n",
    "            ax.legend()\n",
    "\n",
    "    n_frames = t_raw.shape[0]\n",
    "    return FuncAnimation(fig, animate, frames=n_frames, interval=100, repeat=False)\n",
    "\n",
    "def plot_color(z: torch.Tensor, x: torch.Tensor, y: torch.Tensor, n_points_x, n_points_y, title, figsize=(8, 6), dpi=100, cmap=\"viridis\"):\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    z_raw = z.detach().cpu().numpy()\n",
    "    x_raw = x.detach().cpu().numpy()\n",
    "    y_raw = y.detach().cpu().numpy()\n",
    "    X = x_raw.reshape(n_points_x, n_points_y)\n",
    "    Y = y_raw.reshape(n_points_x, n_points_y)\n",
    "    Z = z_raw.reshape(n_points_x, n_points_y)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    c = ax.pcolormesh(X, Y, Z, cmap=cmap)\n",
    "    fig.colorbar(c, ax=ax)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_3D(z: torch.Tensor, x: torch.Tensor, y: torch.Tensor, n_points_x, n_points_y, length: float, floor: torch.Tensor, title, figsize=(8, 6), dpi=100, limit=4):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    z_raw = z.detach().cpu().numpy()\n",
    "    x_raw = x.detach().cpu().numpy()\n",
    "    y_raw = y.detach().cpu().numpy()\n",
    "    X = x_raw.reshape(n_points_x, n_points_y)\n",
    "    Y = y_raw.reshape(n_points_x, n_points_y)\n",
    "    Z = z_raw.reshape(n_points_x, n_points_y)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.axes.set_zlim3d(bottom=0, top=limit)\n",
    "\n",
    "    c = ax.plot_surface(X, Y, Z)\n",
    "\n",
    "    # mesh\n",
    "    x_floor, y_floor, z_floor = dump_points(MESH_FILENAME)\n",
    "    ax.plot_trisurf(x_floor, y_floor, z_floor, linewidth=0.2)\n",
    "\n",
    "\n",
    "    # based on floor function\n",
    "    # x_floor = torch.linspace(0.0, length, floor_steps)\n",
    "    # y_floor = torch.linspace(0.0, length, floor_steps)\n",
    "    # z_floor = torch.zeros((floor_steps, 50))\n",
    "    # for x_idx, x_coord in enumerate(x_floor):\n",
    "    #     for y_idx, y_coord in enumerate(y_floor):\n",
    "    #         z_floor[x_idx, y_idx] = floor(x_coord, y_coord)\n",
    "    # x_floor = torch.tile(x_floor, (50, 1))\n",
    "    # y_floor = torch.tile(y_floor, (50, 1)).T\n",
    "    # f = ax.plot_surface(x_floor, y_floor, z_floor, color='green', alpha=0.7)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3897798,
     "sourceId": 6774114,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3954917,
     "sourceId": 6883680,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4064500,
     "sourceId": 7060245,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
